ğŸ“ AI Personalized Tutor â€” Real-Time Voice Learning Assistant

An interactive AI-powered learning assistant that allows users to ask questions via text or voice and receive step-by-step explanations with voice output.

Built with a modular FastAPI backend and a clean Streamlit frontend, powered by Meta LLaMA-3 (via OpenRouter API).

ğŸ’¬ Speak or type your question â€” the tutor listens, understands context, and responds intelligently.

ğŸ§  Features

ğŸ™ï¸ Voice Input â€” Ask questions naturally using your microphone
âŒ¨ï¸ Text Input â€” Type queries directly into the UI
ğŸ”Š Voice Output (TTS) â€” AI responses are spoken aloud
ğŸ§  Context Memory â€” Maintains last 10 messages for multi-turn interaction
ğŸ” Secure API Handling â€” API keys stored safely in .env
âš¡ Lightweight â€” Runs on CPU, no GPU required
ğŸ–¥ï¸ Interactive UI â€” Clean and simple Streamlit interface
ğŸ—ï¸ Modular Architecture â€” Separate frontend and backend for scalability

ğŸ—ï¸ Tech Stack
Component	Technology
Frontend	Streamlit
Backend	FastAPI
LLM	Meta LLaMA-3 (via OpenRouter API)
Speech Input	Google SpeechRecognition
Speech Output	pyttsx3 (Windows SAPI5)
HTTP Client	Requests
Environment Config	python-dotenv

ğŸ“ Project Structure
AI-Personalized-Tutor/
â”‚
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ main.py        # FastAPI app + API routes
â”‚   â”œâ”€â”€ model.py       # LLaMA-3 integration logic
â”‚   â”œâ”€â”€ config.py      # Environment variable handling
    â”œâ”€â”€ tts.py         # For output Voice 
â”‚   â””â”€â”€ __init__.py
â”‚
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ app.py         # Streamlit UI + Speech Recognition
â”‚   â””â”€â”€ tts.py         # Text-to-Speech service
â”‚
â”œâ”€â”€ .env               # OPENROUTER_API_KEY stored here
â”œâ”€â”€ requirements.txt   # Dependencies
â””â”€â”€ README.md          # Project documentation


Clean separation between frontend and backend ensures modularity and scalability.

ğŸ§  System Architecture
User (Voice / Text)
        â†“
Streamlit Frontend
        â†“
Google SpeechRecognition (if voice)
        â†“
FastAPI Backend
        â†“
OpenRouter API â†’ LLaMA-3
        â†“
AI Response
        â†“
pyttsx3 (Text-to-Speech)
        â†“
Spoken Output to User


The system follows a clientâ€“server architecture, ensuring secure API key management and clean separation of concerns.

ğŸ§° Installation Guide
1ï¸âƒ£ Create Virtual Environment
python -m venv mvenv
mvenv\Scripts\activate   # Windows

2ï¸âƒ£ Install Dependencies
pip install -r requirements.txt

ğŸ” Environment Setup

Create a .env file in the root directory:

OPENROUTER_API_KEY=your_openrouter_api_key_here


Get your API key from:
ğŸ‘‰ https://openrouter.ai

ğŸš€ Run the Application
Step 1: Start Backend
uvicorn backend.main:app --reload


Backend runs at:

http://127.0.0.1:8000

Step 2: Start Frontend
streamlit run frontend/app.py


Open in browser:

http://localhost:8501

ğŸ—£ï¸ Sample Questions to Try

â€œExplain stacks in data structures.â€

â€œWhat is machine learning in simple words?â€

â€œHow does binary search work?â€

â€œWhat is overfitting?â€

â€œSummarize neural networks.â€

ğŸ›ï¸ Controls
Button	Function
ğŸ’¬ Send	Send typed message
ğŸ™ï¸ Speak	Record microphone input
ğŸ”‡ Stop	Stop voice output
ğŸ§¹ Clear	Reset conversation memory
ğŸ§  Learning Outcomes

This project demonstrates:

REST API design with FastAPI

LLM integration using OpenRouter

Secure environment variable handling

Real-time speech-to-text and text-to-speech

Modular system architecture

Error handling and asynchronous operations

âš¡ Future Improvements

ğŸ” JWT Authentication
ğŸ’¾ Persistent chat history (Database)
ğŸ³ Docker containerization
â˜ï¸ Cloud deployment (Render / AWS)
ğŸŒ Multilingual support
ğŸ§  Long-term memory storage

ğŸ‘¨â€ğŸ’» Developer

Chandan Kheto
Passionate about building real-time AI systems and scalable backend applications.

â­ If you found this project interesting, feel free to star the repository!
